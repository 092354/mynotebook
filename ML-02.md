# Supervised Machine Learning: Regression and Classification

## Multiple linear regression

Linear regression model with multiple input features is Multiple linear regression.

### multiple features

#### Terminology
Training set
   > $x_j = j^{th}$ feature
   > 
   > n = number of features
   > 
   > $x^{(i)}$ = features of $i^{th}$ training example
   > 
   > $x_j^{(i)}$ = value of feature j in  $i^{th}$ training example$

Model
   > $f_{w,b}(x) = w_1x_1 + w_2x_2 + ... + w_nx_n + b$
   > 

### Vectorization

#### Vectors
1-D arrays
#### Matrices
2-D arrays


## Gradient descent in practice

### Feature scaling
#### why is it required to do feature scaling
feature size and parameter size


#### how do you scale features
- dividing by the maximum
- mean normalization 

  - you start with the original features and then you re-scale them so that both of them are centered around zero.
  (feature - average)/(maximum-minimum)
- Z-score normalization

  - (feature - average)/standard deviation
  
### Checking gradient descent for convergence
- plot the cost function J, which is calculated on the training set, and I plot the value of J at each iteration of gradient descent.
- Automatic convergence tests:
  - If the cost J decreases by less than this number epsilon on one iteration, then you're likely on this flattened part of the curve that you see on the left and you can declare convergence. 

### Choosing the learning rate
- check if there is bug: choosing a very very small learning rate, the cost function J should decrease after each iteration
- values to try: 0.001 -> 0.003 (3x) -> 0.01 ... -> 1









